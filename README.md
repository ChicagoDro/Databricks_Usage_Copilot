# Who Am I?
**Pete Tamisin** â€“ Technical GTM Leader â€¢ AI & Data Engineering Architect â€¢ Builder & Teacher
Based in Chicago, IL.

* 20+ years designing data & AI platforms (Dir. at Capital One, ex-Databricks, 2x series A startup exits, x-Siemens, x-Motorola)
* Focused on **modern data platforms**, **Context aware RAG systems**, and **enterprise GenAI adoption**
* Passionate about **teaching** and helping teams ship real-world AI systems

ğŸ“§ Email: `pete@tamisin.com`
ğŸ”— LinkedIn: [peter-tamisin-50a3233a](https://www.linkedin.com/in/peter-tamisin-50a3233a/)

---

# Databricks Usage Copilot

An AI-powered analytics copilot for exploring Databricks usage, cost, and reliability.
This project combines **SQL-backed analytics, GraphRAG, and deterministic LLM prompts** to deliver explainable, decision-ready insights â€” without relying on guess-driven chat interactions.

This project ingests structured Databricks-like operational data into:

- A **SQLite database** with realistic usage tables  
- A **FAISS vector index** for semantic retrieval  
- An **in-memory graph** of your environment (org units â†’ users â†’ jobs â†’ runs â†’ usage â†’ events â†’ evictions â†’ SQL queries)  
- A **Graph-aware orchestrator** that performs graph expansion + semantic retrieval  
- A **Streamlit UI** + **CLI** that show both the answer *and* â€œhow the AI reasonedâ€

### ğŸ¯ Project Goals

Provide clear visibility into Databricks usage and cost drivers
Enable reliable drill-downs into jobs, compute types, and execution behavior
Demonstrate how AI can explain data instead of inventing it
Showcase production-style patterns for enterprise AI copilots


---

## Core Design Principle

> **Donâ€™t let the model guess what the user meant.**  
> Use **deterministic reports** to define the question, and use the LLM to explain the result with context.

This is a different (and more enterprise-friendly) UX than â€œchat-first RAGâ€:

- **Reports** define â€œwhat weâ€™re looking atâ€
- **Clicks** define â€œwhat we want explainedâ€
- **Prompts** are deterministic and repeatable
- **LLM** provides narrative, root-cause hypotheses, and next actions

---

## Deterministic Reports (Not Chat Guessing)

Each report is powered by explicit SQL and a known semantic meaning.  
The chart/table is the interface; the AI is the commentary layer.

Example reports (current + planned):

- **Job Cost** â€” stacked horizontal bars by job, segmented by spot vs on-demand ratio
- **Total Cost by Compute Type** â€” recommended as a **sorted bar chart** (not a pie chart)
- **Pareto Job Cost Concentration** â€” cumulative contribution curve / Pareto view
- **Spot Risk Exposure by Job** â€” rank jobs by spot ratio + eviction signals

---

## Deterministic Action Chips (Key Differentiator)

Every meaningful data point in a report produces deterministic â€œaction chipsâ€ (buttons) that trigger a known prompt, for example:

- Clicking a job bar â†’ `Tell me more about job_id = J-...`
- Clicking a compute type â†’ `Explain spend for compute_type = ...`
- Clicking â€œtop driverâ€ â†’ `Explain why this driver is expensive and what to optimize`

If a visualization itself canâ€™t host clickable links cleanly, chips are rendered below the chart as â€œdrill actionsâ€ for the visible marks.

---

## One-Diagram Overview: Report â†’ Selection â†’ Prompt â†’ Answer

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Report (SQL query)    â”‚
â”‚  Chart / Table / KPI   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ click a mark / row / chip
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Selection â†’ Context     â”‚
â”‚ entity_type + entity_id â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ deterministic template
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Prompt Builder          â”‚
â”‚ "Tell me more about ...â”‚
â”‚  include X, Y, Z"       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Commentary Answer   â”‚
â”‚ + optional debug panel  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
````

---

## ğŸ“¦ Dataset Overview

All data is stored in a local **SQLite database**:

```text
data/Databricks_Usage/usage_rag_data.db
````

This database is generated from:

* `data/Databricks_Usage/create_usage_tables.sql` â€” table definitions
* `data/Databricks_Usage/seed_usage_tables.sql` â€” synthetic but realistic seed data
* `database_setup.py` â€” orchestration script that creates & seeds the database

### Tables & Concepts

| Table               | Description                                                  |
| ------------------- | ------------------------------------------------------------ |
| `workspace`        | Organizational units (cost centers)                          |
| `users_lookup`      | Users, departments, and OU membership                        |
| `jobs`              | Scheduled Databricks jobs with metadata + tags               |
| `job_runs`          | Daily executions of jobs with status + cluster settings      |
| `compute_usage`     | DBU usage, cost, instance type, CPU/memory metrics           |
| `non_job_compute`   | SQL Warehouses & All-Purpose Clusters                        |
| `events`            | Cluster lifecycle events and spot eviction-related events    |
| `eviction_details`  | Detailed spot eviction telemetry                             |
| `sql_query_history` | Ad-hoc SQL query executions (user, warehouse, duration, SQL) |
| `date_series`       | Synthetic daily range used to generate runs/usage            |

### Dataset Purpose

The dataset is intentionally **relational** and **interconnected** to mimic real telemetry:

* **Jobs** â†’ **job runs** â†’ **compute usage**
* **Usage** â†’ **events** â†’ **evictions**
* **Users** â†’ **queries** and **org units**

This makes it ideal for demonstrating:

* **Graphs & relationships** (jobs â†’ runs â†’ usage â†’ events â†’ queries)
* **Context assembly via traversal**
* **Hybrid retrieval** (semantic + structural)
* **RAG systems for FinOps / observability / governance**

---

## ğŸ•¸ï¸ Architecture Overview (Graph + Reports + UI)

At a high level:

1. **SQLite DB** holds structured Databricks usage data.
2. The **report registry** defines each report:

   * SQL query
   * visualization type
   * which columns become â€œentitiesâ€
   * chip templates for deterministic prompts
3. The **Streamlit dashboard** renders the chosen report in the visualization pane.
4. User clicks a mark/row/chip â†’ the system builds a deterministic prompt and executes it.
5. The **LLM** returns commentary in the always-present commentary pane.
6. If debug mode is enabled, the UI shows the underlying SQL, prompt, and any additional reasoning artifacts.

### Consolidated System Diagram

```text
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   SQLite Usage DB         â”‚
                 â”‚ (jobs, runs, usage, ...)  â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ SQL
                             â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Reports Registry         â”‚
                 â”‚  - SQL per report         â”‚
                 â”‚  - viz config             â”‚
                 â”‚  - entity mapping         â”‚
                 â”‚  - chip templates         â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Streamlit Dashboard                        â”‚
â”‚  Sidebar: Report links + Debug toggle                         â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Visualization Pane   â”‚   â”‚ Commentary Pane (LLM)         â”‚  â”‚
â”‚  â”‚ (chart/table/KPI)    â”‚   â”‚ "Tell me more about ..."      â”‚  â”‚
â”‚  â”‚ click â†’ context      â”‚   â”‚ + freeform prompt box         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚ selection                 â”‚ deterministic prompt  â”‚
â”‚             â–¼                           â–¼                       â”‚
â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚      â”‚ Prompt Builder + Context Assembler             â”‚         â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                             â–¼                                  â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                      â”‚      LLM      â”‚                          â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ Setup & Installation

> These instructions assume a working Python 3.10+ and `git`.

### 1. Clone the repository

```bash
git clone https://github.com/ChicagoDro/AI-Portfolio
cd AI-Portfolio
```

### 2. Create & activate a virtual environment

**macOS / Linux:**

```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Windows (PowerShell):**

```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

### 3. Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Configure environment variables

Create a `.env` file in the project root with at least:

```env
LLM_PROVIDER=openai          # or gemini, etc.
OPENAI_API_KEY=sk-...        # if using OpenAI

# Optional: override models
# OPENAI_CHAT_MODEL=gpt-4.1-mini
# OPENAI_EMBED_MODEL=text-embedding-3-small
```

---

# ğŸš¦ How to Run the System (Using the Makefile)

This project now includes a convenient **Makefile** to automate the entire workflow:

* Creating the SQLite database
* Building the FAISS vector index
* Launching the Streamlit UI
* Cleaning generated artifacts

You no longer need to manually run `database_setup.py`, `ingest_embed_index.py`, or `streamlit run â€¦`.
Just use `make`.

---

## ğŸ§° Available Make Targets

### **`make db` â€” Create & Seed the SQLite Database**

This target:

1. Runs `database_setup.py`
2. Creates `data/usage_rag_data.db`
3. Executes:

   * `create_usage_tables.sql`
   * `seed_usage_tables.sql`

This gives you a **fully populated Databricks-like usage database**, including:

* Jobs
* Job runs
* Compute usage
* Events
* Evictions
* SQL query history
* Users & org units

---

### **`make index` â€” Build the FAISS Semantic Index**

This target:

1. Runs the full domain ingestion pipeline (`src/ingest_usage_domain.py`)
2. Embeds every usage document
3. Builds a FAISS vector index
4. Saves it to:

```
indexes/usage_faiss/
```

The index is what allows the assistant to:

* Perform semantic retrieval
* Pick anchor nodes
* Trigger graph expansion for GraphRAG

---

### **`make app` â€” Launch the Streamlit UI**

This target:

1. Sets the correct `PYTHONPATH`
2. Boots the Streamlit interface at:

```
http://localhost:8501
```

The UI includes:

* Report navigation in the sidebar
* Visualization pane (charts/tables)
* Commentary pane (LLM)
* Optional debug info (SQL/prompt/context, if enabled)

---

### **`make all` â€” Full Pipeline: DB â†’ Index â†’ UI**

This is the smoothest end-to-end experience.

Running:

```
make all
```

will:

1. Build / rebuild the SQLite database
2. Build / rebuild the FAISS index
3. Launch the Streamlit app immediately

Perfect for first-time setup or after making schema changes.

---

### **`make clean` â€” Remove All Generated Artifacts**

This target deletes:

* The SQLite database
* The FAISS index directory

Useful when:

* You want to regenerate everything from scratch
* You updated the schema or seed data
* Youâ€™re debugging ingestion or graph-building issues

---

## ğŸ¯ Recommended Workflow

To set up the system for the first time:

```bash
make all
```

After that, when you update:

* Seed data â†’ run `make db index`
* Embedding model or ingestion logic â†’ run `make index`
* UI only â†’ run `make app`
* Reset everything â†’ run `make clean && make all`

---

## ğŸ“Œ Under the Hood (What Each Step Actually Does)

| Make Target  | What Happens Internally                                                             |
| ------------ | ----------------------------------------------------------------------------------- |
| `make db`    | Executes Python schema builder â†’ creates all tables â†’ inserts all synthetic records |
| `make index` | Generates RAG docs â†’ computes embeddings â†’ builds FAISS index â†’ stores metadata     |
| `make app`   | Loads report registry â†’ runs report SQL â†’ renders UI â†’ wires clickâ†’promptâ†’LLM loop  |
| `make clean` | Removes SQLite DB + FAISS index folder                                              |
| `make all`   | `db` + `index` + `app`                                                              |

---

## ğŸ“ Project Structure

```text
AI-Portfolio/
  database_setup.py               # SQLite setup + schema population
  .env                            # environment variables (ignored in git)
  requirements.txt                # dependencies

  data/
    create_usage_tables.sql       # Creates Databricks Usage schema
    seed_usage_tables.sql         # Loads sample data
    usage_rag_data.db             # Generated SQLite DB

  indexes/
    usage_faiss/                  # FAISS index (created at runtime)

  src/
    config.py                     # Paths + provider config
    ingest_usage_domain.py        # SQL â†’ RAG docs
    ingest_embed_index.py         # Docs â†’ embeddings â†’ FAISS
    graph_model.py                # Nodes & edges & adjacency (HAS_* edges)
    graph_retriever.py            # Graph-aware retriever (GraphRAG)
    chat_orchestrator.py          # LLM orchestration + routing + debug
    app.py                        # Streamlit UI (reports + commentary)
    reports/                      # Report definitions (SQL + viz + chip mapping)
      registry.py                   # Report registry (navigation + metadata)
```

---

## ğŸ”­ Future Enhancements

* Add richer drill paths (multi-hop exploration) while staying deterministic.
* Add evaluation harnesses (report accuracy checks, LLM groundedness checks).
* Export the in-memory graph into **Neo4j** for large-scale graph analytics.

